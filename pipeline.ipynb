{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2b9ae85",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26ef8399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/indiv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import DirectoryLoader, Docx2txtLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "# from langchain_community.chat_models import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "from langsmith import traceable\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ce966f",
   "metadata": {},
   "source": [
    "# Embedding model\n",
    "\n",
    "BAAI : https://huggingface.co/BAAI/bge-m3\n",
    "\n",
    "intfloat : https://github.com/beir-cellar/beir?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ef78882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g2/p06t4qmx0ys102r1knn051hw0000gn/T/ipykernel_24406/1392817038.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embed_model = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model ready\n"
     ]
    }
   ],
   "source": [
    "embed_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",   # Good at Thai\n",
    "    model_kwargs={\n",
    "        \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# embed_model = HuggingFaceEmbeddings(\n",
    "#     model_name=\"intfloat/multilingual-e5-large\",   # Good at Thai\n",
    "#     model_kwargs={\n",
    "#         \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#     }\n",
    "# )\n",
    "\n",
    "print(\"Embedding model ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca29984",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd86e60",
   "metadata": {},
   "source": [
    "## Train Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f335878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_docs(folder_path):\n",
    "    docs = []\n",
    "\n",
    "    files = sorted(glob.glob(os.path.join(folder_path, \"*.docx\")))\n",
    "\n",
    "    for f in files:\n",
    "        if os.path.basename(f).startswith(\"~$\"):\n",
    "            continue\n",
    "\n",
    "        loader = Docx2txtLoader(f)\n",
    "        doc = loader.load()[0]\n",
    "\n",
    "        docs.append(\n",
    "            Document(\n",
    "                page_content=doc.page_content,\n",
    "                metadata={\"file\": os.path.basename(f)}\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff1ff29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = load_train_docs(\"./dataset/train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa025df",
   "metadata": {},
   "source": [
    "## Val Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2341d626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eval_docs(folder_path):\n",
    "    docs = {}\n",
    "\n",
    "    files = sorted(glob.glob(os.path.join(folder_path, \"*.docx\")))\n",
    "\n",
    "    for f in files:\n",
    "        if os.path.basename(f).startswith(\"~$\"):\n",
    "            continue\n",
    "\n",
    "        loader = Docx2txtLoader(f)\n",
    "        doc = loader.load()[0]\n",
    "\n",
    "        docs[os.path.basename(f)] = doc.page_content\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5541d90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_docs = load_eval_docs(\"./dataset/val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c937e",
   "metadata": {},
   "source": [
    "## Ground Truth Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa5d6226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ground_truth(folder_path):\n",
    "    gt = {}\n",
    "\n",
    "    files = sorted(glob.glob(os.path.join(folder_path, \"*.docx\")))\n",
    "\n",
    "    for f in files:\n",
    "        if os.path.basename(f).startswith(\"~$\"):\n",
    "            continue\n",
    "\n",
    "        loader = Docx2txtLoader(f)\n",
    "        doc = loader.load()[0]\n",
    "\n",
    "        gt[os.path.basename(f)] = doc.page_content\n",
    "\n",
    "    return gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59f315c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = load_ground_truth(\"./dataset/val_measure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dbf431",
   "metadata": {},
   "source": [
    "## Test Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30219134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_dataset(folder_path=\"./dataset/test\"):\n",
    "\n",
    "    test_inputs = {}\n",
    "    test_ground_truth = {}\n",
    "\n",
    "    files = sorted(glob.glob(os.path.join(folder_path, \"*.docx\")))\n",
    "\n",
    "    for f in files:\n",
    "        fname = os.path.basename(f)\n",
    "\n",
    "        # Ignore temporary Word files\n",
    "        if fname.startswith(\"~$\"):\n",
    "            continue\n",
    "\n",
    "        loader = Docx2txtLoader(f)\n",
    "        doc = loader.load()[0]\n",
    "        text = doc.page_content.strip()\n",
    "\n",
    "        if \"มาตรการป้องกัน\" not in text:\n",
    "            print(f\"[WARNING] ไม่พบคำว่า 'มาตรการป้องกัน' ในไฟล์ {fname}\")\n",
    "            continue\n",
    "\n",
    "        parts = text.split(\"มาตรการ\", 1)\n",
    "\n",
    "        incident_text = parts[0].strip()\n",
    "        measure_text = parts[1].strip()\n",
    "\n",
    "        test_inputs[fname] = incident_text\n",
    "        test_ground_truth[fname] = measure_text\n",
    "\n",
    "    print(f\"Loaded {len(test_inputs)} test cases\")\n",
    "\n",
    "    return test_inputs, test_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f17748e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 test cases\n",
      "5\n",
      "['รายงานสืบสวนอุบัติเหตุเชิงลึก_02_Feb19-PattayaChonburi.docx 17-49-22-743.docx', 'รายงานสืบสวนอุบัติเหตุเชิงลึก_05_280268_PickupRoadside.docx', 'รายงานสืบสวนอุบัติเหตุเชิงลึก_15_May03_Minibus.docx']\n"
     ]
    }
   ],
   "source": [
    "test_inputs, test_ground_truth = load_test_dataset()\n",
    "\n",
    "print(len(test_inputs))\n",
    "print(list(test_inputs.keys())[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ade872",
   "metadata": {},
   "source": [
    "# Chunking Embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01be7f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 528\n"
     ]
    }
   ],
   "source": [
    "# chunk_size, chunk_overlap = Hyper Params\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=250,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(train_docs)\n",
    "print(f\"Total chunks: {len(chunks)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e081e4",
   "metadata": {},
   "source": [
    "# ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396b6645",
   "metadata": {},
   "source": [
    "## Drop all data in ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deefeb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# RESET_DB = True\n",
    "\n",
    "# if RESET_DB and os.path.exists(\"./chroma_db\"):\n",
    "#     shutil.rmtree(\"./chroma_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08bd56d",
   "metadata": {},
   "source": [
    "## Append embedding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "206c4a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding & Stored in ChromaDB successfully!\n"
     ]
    }
   ],
   "source": [
    "# Don't forget to create /chroma_db folder\n",
    "\n",
    "persist_directory = \"./chroma_db\"\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embed_model,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "print(\"Embedding & Stored in ChromaDB successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825f8e9d",
   "metadata": {},
   "source": [
    "# (Retrieval Evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b78a48d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de6c2ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Doc 1 ---\n",
      "Source: {'file': '2025-05-29 รายงานสืบสวนอุบัติเหตุเชิงลึก_RUTS-250315-07.docx'}\n",
      "ผู้ขับขี่รถยนต์เก๋งเป็นเพศชาย อายุ 28 ปี สัญชาติไทย มีใบอนุญาตขับขี่รถยนต์ส่วนบุคคล ตรวจไม่พบปริมาณแอลกอฮอล์ในร่างกาย และไม่มีโรคประจำตัวที่อาจส่งผลต่อพฤติกรรมการขับขี่ ในวันเกิดเหตุ ผู้ขับขี่เดินทางกลับจากอำเภอขนอม มุ่งหน้าไปยังที่พักในอำเภอนบพิตำ\n",
      "\n",
      "--- Doc 2 ---\n",
      "Source: {'file': '2025-05-29 รายงานสืบสวนอุบัติเหตุเชิงลึก_RUTS-250315-07.docx'}\n",
      "จากการสอบถามข้อมูลจากเจ้าหน้าที่ตำรวจและผู้ที่เกี่ยวข้อง ทราบว่า รถยนต์เก๋ง Mercedes-Benz สีขาว ขับขี่โดยชายไทย อายุ 28 ปี พร้อมผู้โดยสารอีก 2 ราย เดินทางกลับจากกิจกรรมคอนเสิร์ตในพื้นที่อำเภอขนอม ซึ่งห่างจากที่เกิดเหตุประมาณ 40 กิโลเมตร\n",
      "\n",
      "--- Doc 3 ---\n",
      "Source: {'file': '2025-05-29 รายงานสืบสวนอุบัติเหตุเชิงลึก_RUTS-250315-07.docx'}\n",
      "ตารางที่ ‎3-1 ข้อมูลทางกายภาพ และข้อมูลการบาดเจ็บและเสียชีวิต\n",
      "\n",
      "ตำแหน่ง\n",
      "\n",
      "เพศ\n",
      "\n",
      "สัญชาติ\n",
      "\n",
      "อายุ\n",
      "\n",
      "เข็มขัดนิรภัย\n",
      "\n",
      "ระดับการบาดเจ็บ\n",
      "\n",
      "D1\n",
      "\n",
      "ชาย\n",
      "\n",
      "ไทย\n",
      "\n",
      "28\n",
      "\n",
      "ใช้งาน\n",
      "\n",
      "AIS 1 (แน่นหน้าอก)\n",
      "\n",
      "11\n",
      "\n",
      "ชาย\n",
      "\n",
      "ไทย\n",
      "\n",
      "26\n",
      "\n",
      "ใช้งาน\n",
      "\n",
      "AIS1 (บาดเจ็บเล็กน้อย)\n",
      "\n",
      "21\n",
      "\n",
      "ชาย\n",
      "\n",
      "ไทย\n",
      "\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Test without Scores\n",
    "\"\"\"\n",
    "\n",
    "# docs = retriever.invoke(\"2 มกราคม 2568 เกิดอะไรขึ้น\")\n",
    "# docs = retriever.invoke(\"19 กุมภาพันธ์ 2568 เกิดอะไรขึ้น\")\n",
    "# docs = retriever.invoke(\"กิโลเมตรที่ 239+100\")\n",
    "docs = retriever.invoke(\"ชาย 28 ที่เป็นคนไทย\")\n",
    "\n",
    "# print(docs[0].page_content)\n",
    "for i, d in enumerate(docs):\n",
    "    print(f\"\\n--- Doc {i+1} ---\")\n",
    "    print(\"Source:\", d.metadata)\n",
    "    print(d.page_content[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24f3c2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9140981435775757\n",
      "Source: {'file': '2025-05-29 รายงานสืบสวนอุบัติเหตุเชิงลึก_RUTS-250315-07.docx'}\n",
      "ผู้ขับขี่รถยนต์เก๋งเป็นเพศชาย อายุ 28 ปี สัญชาติไทย มีใบอนุญาตขับขี่รถยนต์ส่วนบุคคล ตรวจไม่พบปริมาณแอลกอฮอล์ในร่างกาย และไม่มีโรคประจำตัวที่อาจส่งผลต่อพฤติกรรมการขับขี่ ในวันเกิดเหตุ ผู้ขับขี่เดินทางก\n",
      "-----\n",
      "Score: 0.9839334487915039\n",
      "Source: {'file': '2025-06-03 รายงานสืบสวนอุบัติเหตุเชิงลึก_RUTS-250417-10.docx'}\n",
      "และมีผู้โดยสารร่วมเดินทางมาด้วย 1 ราย เป็นหญิงไทย อายุ 23 ปี\n",
      "-----\n",
      "Score: 0.9969594478607178\n",
      "Source: {'file': '2025-05-29 รายงานสืบสวนอุบัติเหตุเชิงลึก_RUTS-250315-07.docx'}\n",
      "ผู้ขับขี่รถยนต์เก๋งเป็นชาย อายุ 28 ปี เดินทางพร้อมเพื่อนชายอีก 1 ราย หลังจากร่วมชมคอนเสิร์ตในพื้นที่อำเภอขนอม และกำลังมุ่งหน้ากลับบ้านพักในอำเภอนบพิตำ เมื่อเดินทางถึงบริเวณสี่แยกบ้านต้นเหรียง ซึ่งเป็น\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Test with Scores\n",
    "\"\"\"\n",
    "\n",
    "search_msg = \"คนไทย อายุ 28\"\n",
    "# search_msg = \"2 มกราคม 2568 เกิดอะไรขึ้น\"\n",
    "\n",
    "docs_with_scores = vectorstore.similarity_search_with_score(\n",
    "    search_msg,\n",
    "    k=3\n",
    ")\n",
    "\n",
    "\n",
    "for doc, score in docs_with_scores:\n",
    "    print(\"Score:\", score)\n",
    "    print(\"Source:\", doc.metadata)\n",
    "    print(doc.page_content[:200])\n",
    "    print(\"-----\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6559b7",
   "metadata": {},
   "source": [
    "# LangSmith\n",
    "\n",
    "Logging token and prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c674162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable\n",
    "\n",
    "@traceable(name=\"LLM1-Tool-Selection\")\n",
    "def run_llm1(messages):\n",
    "    return llm_with_tools.invoke(messages)\n",
    "\n",
    "\n",
    "@traceable(name=\"Vector-Search\")\n",
    "def run_retrieval(query):\n",
    "    return search_db.invoke(query)\n",
    "\n",
    "\n",
    "@traceable(name=\"LLM2-Final-Reasoning\")\n",
    "def run_llm2(messages):\n",
    "    return llm_final.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d421c4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"RAG-Agent-Pipeline\")\n",
    "def run_pipeline(question: str):\n",
    "\n",
    "    messages = [HumanMessage(content=question)]\n",
    "\n",
    "    response = run_llm1(messages)\n",
    "\n",
    "    if not response.tool_calls:\n",
    "        return response.content\n",
    "\n",
    "    query = response.tool_calls[0][\"args\"][\"query\"]\n",
    "    tool_result = run_retrieval(query)\n",
    "\n",
    "    tool_message = ToolMessage(\n",
    "        content=tool_result,\n",
    "        tool_call_id=response.tool_calls[0][\"id\"]\n",
    "    )\n",
    "\n",
    "    final = run_llm2(messages + [response, tool_message])\n",
    "\n",
    "    return final.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f56c97",
   "metadata": {},
   "source": [
    "# LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952c8be1",
   "metadata": {},
   "source": [
    "## Blind LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2e4d602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature = Hyper param\n",
    "# LOW=Exactly in resource   HIGH=Creative\n",
    "\n",
    "llm_blind = ChatOpenAI(\n",
    "    model=\"qwen2.5\",\n",
    "    openai_api_key=\"ollama\",\n",
    "    openai_api_base=\"http://localhost:11434/v1\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# llm_blind = ChatOllama(\n",
    "#     model=\"qwen2.5\",\n",
    "#     temperature=0.1\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1740036",
   "metadata": {},
   "source": [
    "## Function Tools\n",
    "Customize functions: the description & function name must be MEANINGFUL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f2e8b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_db(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search the accident investigation document database.\n",
    "\n",
    "    Use this tool when the user asks about:\n",
    "    - Specific accident reports\n",
    "    - Dates of incidents\n",
    "    - Causes of accidents\n",
    "    - Number of injured or dead\n",
    "    - Details inside official documents\n",
    "\n",
    "    The query should be a concise search phrase in Thai,\n",
    "    containing important keywords such as report ID,\n",
    "    date, location, or accident type.\n",
    "\n",
    "    Do NOT use this tool for general knowledge questions.\n",
    "    \"\"\"\n",
    "    docs = retriever.invoke(query)\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0016155f",
   "metadata": {},
   "source": [
    "## LLM with Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac528866",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm_blind.bind_tools([search_db])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35648530",
   "metadata": {},
   "source": [
    "## Get Input from user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1652e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_input = input(\"Please describe the situation: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "693dd3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_extract_prompt(user_input: str) -> str:\n",
    "    return f\"\"\"\n",
    "<Instruction>\n",
    "You are an expert accident investigation analyst.\n",
    "\n",
    "Your task is to extract structured key information from the incident description provided in <Input>.\n",
    "\n",
    "You MUST:\n",
    "1. Extract only factual information explicitly stated in the input.\n",
    "2. Do NOT infer, assume, or add any information not clearly mentioned.\n",
    "3. Return the result strictly in valid JSON format.\n",
    "4. If a field is not mentioned, return null.\n",
    "5. Use concise but precise wording.\n",
    "</Instruction>\n",
    "\n",
    "<Context>\n",
    "The structured output will be used to retrieve similar accident investigation cases \n",
    "from an internal database of .docx investigation reports.\n",
    "Accuracy and structure are critical.\n",
    "</Context>\n",
    "\n",
    "<Input>\n",
    "{user_input}\n",
    "</Input>\n",
    "\n",
    "<Output_Format>\n",
    "Return ONLY valid JSON with the following structure:\n",
    "\n",
    "{{\n",
    "  \"incident_type\": \"\",\n",
    "  \"vehicles_involved\": [],\n",
    "  \"environmental_conditions\": \"\",\n",
    "  \"location_type\": \"\",\n",
    "  \"casualties\": {{\n",
    "    \"injured\": 0,\n",
    "    \"fatalities\": 0\n",
    "  }},\n",
    "  \"immediate_causes\": [],\n",
    "  \"contributing_factors\": []\n",
    "}}\n",
    "\n",
    "</Output_Format>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f7b16e",
   "metadata": {},
   "source": [
    "## Final LLM\n",
    "Gathering HumanMessage, Generate Input and Tool Message together to be New Input for generating Final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b64fe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_final = ChatOpenAI(\n",
    "    model=\"qwen2.5\",\n",
    "    openai_api_key=\"ollama\",\n",
    "    openai_api_base=\"http://localhost:11434/v1\",\n",
    "    temperature=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c55b981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_final_prompt(user_input: str,\n",
    "                       structured_data: str,\n",
    "                       retrieved_docs: list) -> str:\n",
    "    \"\"\"\n",
    "    Build the final generation prompt for mitigation recommendation.\n",
    "    \"\"\"\n",
    "\n",
    "    context_text = \"\\n\\n\".join(\n",
    "        [doc.page_content for doc in retrieved_docs]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "<Instruction>\n",
    "You are a senior accident investigation and safety policy expert.\n",
    "\n",
    "Your task is to generate appropriate mitigation measures for the incident described in <Input>, \n",
    "using ONLY the information contained in <Retrieved_Context>.\n",
    "\n",
    "STRICT RULES:\n",
    "1. You MUST base your reasoning strictly on the retrieved .docx investigation reports.\n",
    "2. Do NOT use external knowledge.\n",
    "3. Do NOT fabricate new policies.\n",
    "4. If information is insufficient, state clearly: \"Insufficient information in retrieved documents.\"\n",
    "5. The answer must be logically derived from patterns, principles, or measures found in the retrieved documents.\n",
    "6. The response must be structured and professional.\n",
    "\n",
    "</Instruction>\n",
    "\n",
    "<Context>\n",
    "The structured extraction below was generated to retrieve similar cases.\n",
    "Use it to understand the nature of the incident.\n",
    "</Context>\n",
    "\n",
    "<Structured_Extraction>\n",
    "{structured_data}\n",
    "</Structured_Extraction>\n",
    "\n",
    "<Input>\n",
    "{user_input}\n",
    "</Input>\n",
    "\n",
    "<Retrieved_Context>\n",
    "{context_text}\n",
    "</Retrieved_Context>\n",
    "\n",
    "<Output_Format>\n",
    "\n",
    "### 1. Key Risk Factors\n",
    "- Bullet points summarizing major risks identified.\n",
    "\n",
    "### 2. Recommended Mitigation Measures\n",
    "- Concrete and actionable measures.\n",
    "- Must align with principles found in retrieved documents.\n",
    "\n",
    "### 3. Justification\n",
    "- Explain how the measures are derived from the retrieved cases.\n",
    "\n",
    "</Output_Format>\n",
    "\"\"\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a2b3e5",
   "metadata": {},
   "source": [
    "# Define Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14c93d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(text_input):\n",
    "    \n",
    "    # Extract\n",
    "    extract_prompt = build_extract_prompt(text_input)\n",
    "    extracted = llm_with_tools.invoke(extract_prompt).content\n",
    "    \n",
    "    # Retrieve\n",
    "    retrieved_docs = retriever.invoke(extracted)\n",
    "    \n",
    "    # Final generation\n",
    "    final_prompt = build_final_prompt(\n",
    "        text_input,\n",
    "        extracted,        # structured_data\n",
    "        retrieved_docs    # list of docs\n",
    "    )\n",
    "    \n",
    "    final_answer = llm_final.invoke(final_prompt)\n",
    "    \n",
    "    return final_answer.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb59a525",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71a0393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Similarity\n",
    "\n",
    "def evaluate_similarity(pred, gt, embed_model):\n",
    "    v1 = np.array(embed_model.embed_query(pred))\n",
    "    v2 = np.array(embed_model.embed_query(gt))\n",
    "\n",
    "    # Normalize vectors\n",
    "    v1 = v1 / (np.linalg.norm(v1) + 1e-10)\n",
    "    v2 = v2 / (np.linalg.norm(v2) + 1e-10)\n",
    "\n",
    "    return float(np.dot(v1, v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3b7296",
   "metadata": {},
   "source": [
    "## with Val Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c07b0f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: รายงานสืบสวนอุบัติเหตุเชิงลึก_KU-250305-57.docx\n",
      "Processing: รายงานสืบสวนอุบัติเหตุเชิงลึก_KU-250312-67.docx\n",
      "Processing: รายงานสืบสวนอุบัติเหตุเชิงลึก_KU-250322-71.docx\n",
      "Processing: รายงานสืบสวนอุบัติเหตุเชิงลึก_NU-250109-01.docx\n",
      "Processing: รายงานสืบสวนอุบัติเหตุเชิงลึก_NU-250608-01.docx\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "\n",
    "for fname, case_text in val_docs.items():\n",
    "    print(\"Processing:\", fname)\n",
    "    prediction = run_pipeline(case_text)\n",
    "    predictions[fname] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfbafc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "รายงานสืบสวนอุบัติเหตุเชิงลึก_KU-250305-57.docx => 0.6069657875113526\n",
      "รายงานสืบสวนอุบัติเหตุเชิงลึก_KU-250312-67.docx => 0.6492311301831859\n",
      "รายงานสืบสวนอุบัติเหตุเชิงลึก_KU-250322-71.docx => 0.5936545595128556\n",
      "รายงานสืบสวนอุบัติเหตุเชิงลึก_NU-250109-01.docx => 0.5801891977334518\n",
      "รายงานสืบสวนอุบัติเหตุเชิงลึก_NU-250608-01.docx => 0.6424298266688377\n",
      "\n",
      "##################################################\n",
      "\n",
      "Scores list: [0.6069657875113526, 0.6492311301831859, 0.5936545595128556, 0.5801891977334518, 0.6424298266688377]\n",
      "Length: 5\n",
      "Average: 0.6144941003219367\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for fname in predictions:\n",
    "    if fname in ground_truth:\n",
    "        score = evaluate_similarity(\n",
    "            predictions[fname],\n",
    "            ground_truth[fname],\n",
    "            embed_model\n",
    "        )\n",
    "\n",
    "        print(fname, \"=>\", score)\n",
    "\n",
    "        if not np.isnan(score):\n",
    "            scores.append(score)\n",
    "\n",
    "print('\\n' + \"#\"*50 + '\\n')\n",
    "print(\"Scores list:\", scores)\n",
    "print(\"Length:\", len(scores))\n",
    "print(\"Average:\", np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5eaf8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FILE: รายงานสืบสวนอุบัติเหตุเชิงลึก_KU-250305-57.docx\n",
      "================================================================================\n",
      "\n",
      "PREDICTION:\n",
      "\n",
      "### 1. Key Risk Factors\n",
      "\n",
      "- **Driver Fatigue:** The driver of the motorcycle was experiencing symptoms of drowsiness and sleepiness.\n",
      "- **Excessive Speeding:** The car was traveling at a speed significantly higher than the legal limit (over 120 km/h).\n",
      "- **Lack of Defensive Driving:** The driver did not attempt to avoid or brake upon noticing the obstacle.\n",
      "\n",
      "### 2. Recommended Mitigation Measures\n",
      "\n",
      "1. **Driver Fatigue Management:**\n",
      "   - Implement mandatory rest periods for drivers, especially during long journeys.\n",
      "   - Provide educational programs on recognizing and managing fatigue symptoms among drivers.\n",
      "   \n",
      "2. **Speed Control Measures:**\n",
      "   - Install speed monitoring devices in vehicles to enforce speed limits effectively.\n",
      "   - Increase the number of speed cameras along high-risk routes.\n",
      "\n",
      "3. **Enhanced Defensive Driving Training:**\n",
      "   - Develop and promote defensive driving courses for all road users, focusing on recognizing potential hazards and taking appropriate actions.\n",
      "   - Encourage drivers to maintain a safe distance from other vehicles and be prepared to react quickly to unexpected situations.\n",
      "\n",
      "### 3. Justification\n",
      "\n",
      "- The identified risk factors in the retrieved document highlight that driver fatigue and excessive speeding were significant contributors to the accident. These measures are derived directly from the analysis of similar incidents, emphasizing the need for comprehensive interventions to address these critical issues.\n",
      "  \n",
      "By implementing these mitigation measures, we can reduce the likelihood of such accidents occurring in the future, thereby enhancing road safety and preventing potential fatalities.\n",
      "\n",
      "GROUND TRUTH:\n",
      "\n",
      "โครงการจ้างที่ปรึกษาเพื่อสืบสวนสอบสวนอุบัติเหตุเชิงลึก                             รหัสกรณีอุบัติเหตุ KU-25014-01\n",
      "\n",
      "มาตรการป้องกันและแก้ไข\n",
      "\n",
      "มาตรการระยะสั้น\n",
      "\n",
      "ถนนช่วงบริเวณที่เกิดอุบัติเหตุบนทางหลวงหมายเลข 4 (บ้านโป่ง–เพชรบุรี) กิโลเมตรที่ 94+116\n",
      "เป็นทางหลวงสายหลักที่เชื่อมต่อระหว่างจังหวัดราชบุรีและเพรชบุรี มีลักษณะทางกายภาพเป็นถนนตรงยาวต่อเนื่องหลายกิโลเมตร ทำให้ผู้ขับขี่ต้องขับเป็นทางตรงยาวตลอดทาง การจราจรไม่หนาแน่น และการขับรถในเส้นทางที่ไม่มีการเปลี่ยนแปลงของทัศนียภาพหรือไม่มีสิ่งดึงดูดอาจทำให้เกิดอาการ \"เหนื่อยล้า\" ซึ่งเพิ่มโอกาสให้เกิดการหลับใน และใช้ความเร็วสูง เมื่อใช้ความเร็วสูงและไม่มีสิ่งเร้าภายนอก อาจทำให้ผู้ขับขี่เกิดภาวะง่วงซึมและเผลอหลับในได้ ดังนั้นสำหรับมาตรการระยะสั้นเสนอแนะให้ติดตั้งป้ายเตือนเพิ่มเติมเป็นระยะ ๆ เพื่อให้ผู้ขับขี่เปลี่ยนแปลงความสนใจมาที่ป้ายเตือน ซึ่งช่วยลดความเสี่ยงต่อการหลับในของผู้ขับขี่ยานพาหนะ ดังแสดงในรูปที่ 51 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "รูปที่ 51 ป้ายเตือน “ง่วงจอดพัก”\n",
      "\n",
      "มาตรการระยะยาว\n",
      "\n",
      "\tสำหรับมาตรการระยะยาวที่ช่วยลดความเสี่ยงต่อการเกิดอุบัติเหตุที่มีสาเหตุมาจากการหลับในสามารถแบ่งออกเป็น 2 ส่วน คือ 1) การป้องกันที่ถนนโดยการติดตั้งแถบสั่นเตือน (Transverse Rumble Strips) บนไหล่ทางและกลางถนน ซึ่งวิธีการดังกล่าวจะทำให้เกิดการสั่นสะเทือนหรือเสียงดังเมื่อรถเบี่ยงออกจากเลนหรือออกนอกไหล่ทาง เสียงสั่นสะเทือนจะปลุกผู้ขับขี่ให้ตื่นตัว ลดอุบัติเหตุที่เกิดจากการหลับในและเหม่อลอย ดังแสดงในรูปที่ 5-2  2) ปรับปรุงพื้นผิวถนนและเครื่องหมายจราจรให้มองเห็นได้ชัดเจนทั้งในเวลากลางวันและกลางคืน และ 3) การป้องกันที่ยานพาหนะโดยนำเทคโนโลยี ปัญญาประดิษฐ์ (AI) และการวิเคราะห์วิดีโอ มาช่วยตรวจจับและวิเคราะห์พฤติกรรมของผู้ขับขี่ในแบบเรียลไทม์ เช่น ความง่วงนอน การเสียสมาธิ และการขับขี่ที่เสี่ยงต่อการเกิดอุบัติเหตุ รวมถึงสามารถใช้ข้อมูลที่ได้รับมาประมวลผลผ่านระบบ คลาวด์ เพื่อแจ้งเตือนต่อผู้ขับขี่ ดังแสดงในรูปที่ 5-3 แต่เนื่องจากการเข้าถึงเทคโนโลยีดังกล่าวยังเป็นเรื่องยากการบังคับใช้กับผู้ขับขี่ยานพาหนะทุกคนอาจต้องใช้เวลา ดังนั้นในขั้นเริ่มต้นควรนำเทคโนโลยีมาใช้กับกลุ่มรถขนส่งสาธารณะเพื่อเพิ่มความปลอดภัยแก่ผู้ขับขี่และผู้โดยสาร\n",
      "\n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      "\n",
      "  \n",
      "\n",
      "รูปที่ 52 Transverse Rumble Strips\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "รูปที่ 53 AI Tracks สำหรับผู้ขับขี่\n",
      "\n",
      "\n",
      "\n",
      "จากเหตุการณ์อุบัติเหตุดังกล่าว เนื่องจากลักษณะทางกายภาพของถนนหมายเลข 4 (บ้านโป่ง–เพชรบุรี) กิโลเมตรที่ 94+116 ตำบลท่าราบ อำเภอเมือง จังหวัดราชบุรี เป็นถนนที่เป็นเส้นตรงและไม่มีป้ายกำกับ อำนวยความสะดวกหรือเตือนผู้ใช้ทาง ดังนั้นสำหรับมาตรการที่อาจต้องดำเนินการในขั้นแรก คือ การติดตั้งป้ายเตือน “ง่วงจอดพัก” แจ้งเตือนประชาชนผู้ใช้รถใช้ถนนเป็นระยะเพื่อลดการเกิดอุบัติเหตุบนท้องถนนที่มีสาเหตุอันเนื่องจากการหลับใน\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tศูนย์ปฏิบัติการความปลอดภัยคมนาคม สำนักงานปลัดกระทรวงคมนาคม\t\t101 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tศูนย์ปฏิบัติการความปลอดภัยคมนาคม สำนักงานปลัดกระทรวงคมนาคม\t\t2\n",
      "\n",
      "Similarity Score: 0.6069657875113526\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Script: Test only 1 Val Docs\n",
    "'''\n",
    "\n",
    "fname = \"รายงานสืบสวนอุบัติเหตุเชิงลึก_KU-250305-57.docx\"\n",
    "\n",
    "pred_text = predictions[fname]\n",
    "gt_text = ground_truth[fname]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FILE:\", fname)\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nPREDICTION:\\n\")\n",
    "print(pred_text)\n",
    "\n",
    "print(\"\\nGROUND TRUTH:\\n\")\n",
    "print(gt_text)\n",
    "\n",
    "score = evaluate_similarity(pred_text, gt_text, embed_model)\n",
    "print(\"\\nSimilarity Score:\", score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dac13d",
   "metadata": {},
   "source": [
    "## with Test Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c4fe46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: รายงานสืบสวนอุบัติเหตุเชิงลึก_02_Feb19-PattayaChonburi.docx 17-49-22-743.docx\n",
      "Processing: รายงานสืบสวนอุบัติเหตุเชิงลึก_05_280268_PickupRoadside.docx\n",
      "Processing: รายงานสืบสวนอุบัติเหตุเชิงลึก_15_May03_Minibus.docx\n",
      "Processing: รายงานสืบสวนอุบัติเหตุเชิงลึก_PSU-250512-01.docx\n",
      "Processing: รายงานสืบสวนอุบัติเหตุเชิงลึก_PSU-250620-01.docx\n"
     ]
    }
   ],
   "source": [
    "test_predictions = {}\n",
    "\n",
    "for fname, case_text in test_inputs.items():\n",
    "    print(\"Processing:\", fname)\n",
    "    prediction = run_pipeline(case_text)\n",
    "    test_predictions[fname] = prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77fda8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "รายงานสืบสวนอุบัติเหตุเชิงลึก_02_Feb19-PattayaChonburi.docx 17-49-22-743.docx => 0.7002609991918045\n",
      "รายงานสืบสวนอุบัติเหตุเชิงลึก_05_280268_PickupRoadside.docx => 0.6509822222282975\n",
      "รายงานสืบสวนอุบัติเหตุเชิงลึก_15_May03_Minibus.docx => 0.7013152272504422\n",
      "รายงานสืบสวนอุบัติเหตุเชิงลึก_PSU-250512-01.docx => 0.66280872943394\n",
      "รายงานสืบสวนอุบัติเหตุเชิงลึก_PSU-250620-01.docx => 0.6682452456495097\n",
      "\n",
      "##################################################\n",
      "\n",
      "Test Scores: [0.7002609991918045, 0.6509822222282975, 0.7013152272504422, 0.66280872943394, 0.6682452456495097]\n",
      "Length: 5\n",
      "Average Test Score: 0.6767224847507988\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "\n",
    "for fname in test_predictions:\n",
    "    if fname in test_ground_truth:\n",
    "        score = evaluate_similarity(\n",
    "            test_predictions[fname],\n",
    "            test_ground_truth[fname],\n",
    "            embed_model\n",
    "        )\n",
    "\n",
    "        print(fname, \"=>\", score)\n",
    "\n",
    "        if not np.isnan(score):\n",
    "            test_scores.append(score)\n",
    "\n",
    "print(\"\\n\" + \"#\"*50 + \"\\n\")\n",
    "print(\"Test Scores:\", test_scores)\n",
    "print(\"Length:\", len(test_scores))\n",
    "print(\"Average Test Score:\", np.mean(test_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indiv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
